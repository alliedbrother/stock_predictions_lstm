{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from fredapi import Fred\n",
    "import numpy as np\n",
    "import pandas_ta as ta\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')  # Options: 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'FATAL'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_inference_data(company_df, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Prepare input data for inference .\n",
    "    Args:\n",
    "        company_df (DataFrame): The DataFrame for a specific company.\n",
    "        sequence_length (int): The number of past days to consider as input.\n",
    "\n",
    "    Returns:\n",
    "        numpy array: The input data ready for prediction.\n",
    "    \"\"\"\n",
    "    # Ensure data is sorted by date\n",
    "    company_df = company_df.sort_index()\n",
    "\n",
    "    # Select relevant input features (exclude targets)\n",
    "    input_features = company_df.filter(regex=\"^(?!.*target).*\").values\n",
    "\n",
    "    # Take the last `sequence_length` days as input for prediction\n",
    "    if len(input_features) >= sequence_length:\n",
    "        input_sequence = input_features[-sequence_length:]\n",
    "        return np.expand_dims(input_sequence, axis=0)  # Add batch dimension\n",
    "    else:\n",
    "        raise ValueError(\"Insufficient data for inference (less than sequence length).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_for_all_companies(all_dfs, model, sequence_length=60):\n",
    "    \"\"\"\n",
    "    Get predictions for all companies using the trained model.\n",
    "    Args:\n",
    "        all_dfs (dict): Dictionary of company DataFrames.\n",
    "        model: Trained LSTM model.\n",
    "        sequence_length (int): Number of past days to consider as input.\n",
    "\n",
    "    Returns:\n",
    "        dict: Predictions for each company.\n",
    "    \"\"\"\n",
    "    predictions = {}\n",
    "    \n",
    "    for company, df in all_dfs.items():\n",
    "        try:\n",
    "            # Prepare data for inference\n",
    "            input_data = prepare_inference_data(df, sequence_length=sequence_length)\n",
    "            \n",
    "            # Make predictions\n",
    "            pred = model.predict(input_data)\n",
    "            \n",
    "            # Store predictions\n",
    "            predictions[company] = pred.flatten()  # Flatten the array for readability\n",
    "        \n",
    "        except ValueError as e:\n",
    "            print(f\"Skipping {company}: {e}\")\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading():\n",
    "    start_date = (datetime.datetime.today() - datetime.timedelta(days=100)).strftime('%Y-%m-%d')\n",
    "    end_date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Example list of S&P 500 tickers (full list can be obtained elsewhere)\n",
    "    tickers = [\"AAPL\", \"NVDA\", \"MSFT\", \"GOOG\", \"GOOGL\", \"AMZN\", \"META\", \"AVGO\", \"LLY\", \"TSLA\", \n",
    "                    \"WMT\", \"JPM\", \"V\", \"XOM\", \"UNH\", \"ORCL\", \"MA\", \"HD\", \"PG\", \"COST\", \"JNJ\", \n",
    "                    \"NFLX\", \"ABBV\", \"BAC\", \"KO\", \"CRM\", \"CVX\", \"MRK\", \"TMUS\", \"AMD\", \"PEP\", \n",
    "                    \"ACN\", \"LIN\", \"TMO\", \"MCD\", \"CSCO\", \"ADBE\", \"WFC\", \"IBM\", \"GE\", \"ABT\", \n",
    "                    \"DHR\", \"AXP\", \"MS\", \"CAT\", \"NOW\", \"QCOM\", \"PM\", \"ISRG\", \"VZ\"]\n",
    "\n",
    "    # Download data for all tickers at once\n",
    "    stock_price_data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker')\n",
    "\n",
    "    stock_data = stock_price_data.copy()\n",
    "\n",
    "    # Flatten MultiIndex columns in stock_data\n",
    "    stock_data.columns = ['_'.join(col).strip() for col in stock_data.columns.values]\n",
    "\n",
    "    # Convert index to DatetimeIndex if not already\n",
    "    if not isinstance(stock_data.index, pd.DatetimeIndex):\n",
    "        stock_data.index = pd.to_datetime(stock_data.index)\n",
    "\n",
    "    # Sort by date\n",
    "    stock_data.sort_index(inplace=True)\n",
    "\n",
    "    with open('updated_all_dfs.pkl', 'rb') as file:\n",
    "        loaded_data = pickle.load(file)\n",
    "    \n",
    "    inference_data = {}\n",
    "\n",
    "    for comp in tickers:\n",
    "        ll = 'df_'+comp\n",
    "        reg = '^'+comp+'_'\n",
    "        filtered_data = stock_data.filter(regex=reg)\n",
    "        last_rows = loaded_data[ll].tail(filtered_data.shape[0])\n",
    "        ind_ = filtered_data.index\n",
    "        last_rows.index = ind_\n",
    "        merged_df = filtered_data.join(last_rows, how='left', lsuffix='', rsuffix='_r')\n",
    "        merged_df = merged_df[[col for col in merged_df.columns if not col.endswith('_r')]]\n",
    "        inference_data[ll] = merged_df\n",
    "            \n",
    "    return inference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_predictions():\n",
    "    \n",
    "    inference_data = data_loading()\n",
    "    print(\"Loading data Completed\")    \n",
    "    new_model = load_model('lstm_model_general.h5')\n",
    "    print(\"Loading LSTM model Completed\")\n",
    "    predictions = get_predictions_for_all_companies(inference_data, new_model, sequence_length=60)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    lstm_preds = lstm_predictions()\n",
    "    return lstm_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  50 of 50 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 14:29:45.671246: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-12-12 14:29:45.671985: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-12-12 14:29:45.672674: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-12-12 14:29:45.778978: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-12-12 14:29:45.779641: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-12-12 14:29:45.780227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LSTM model Completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 14:29:45.962755: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-12-12 14:29:45.963772: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-12-12 14:29:45.964614: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-12-12 14:29:46.093446: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-12-12 14:29:46.094321: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-12-12 14:29:46.095145: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 434ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n"
     ]
    }
   ],
   "source": [
    "vals = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project_thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
